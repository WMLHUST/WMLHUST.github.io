{"meta":{"title":"小本本","subtitle":"学而时习之，不亦说乎","description":"厉害了~","author":"WordGe","url":"http://yoursite.com","root":"/"},"pages":[{"title":"categories","date":"2020-05-11T09:14:14.000Z","updated":"2020-05-11T09:14:36.963Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2020-05-11T09:20:22.000Z","updated":"2020-05-11T09:22:25.642Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"about about"},{"title":"tags","date":"2020-05-11T09:10:36.000Z","updated":"2020-05-11T09:11:52.492Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"python多元赋值的一个顺序问题","slug":"python多元赋值的一个坑","date":"2020-07-12T10:50:22.000Z","updated":"2020-07-12T10:50:22.000Z","comments":true,"path":"2020/07/12/python多元赋值的一个坑/","link":"","permalink":"http://yoursite.com/2020/07/12/python%E5%A4%9A%E5%85%83%E8%B5%8B%E5%80%BC%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/","excerpt":"","text":"起因是试验一个python翻转链表的代码，python的变量交换非常方便，比如交换两个元素，可以直接a, b = b, a，因此翻转链表，可以这么写： 1234567def reverseList(head: ListNode) : pre = None cur = head while cur is not None: cur, pre, cur.next = cur.next, cur, pre return pre 然而，这个代码是错误的。 \b经过单步debug，发现在第一次交换发生时，交换的结果就不对。不用怀疑，如果是 a, b, c = b, c, a，那肯定是对的。所以问题出在哪里？不会是python的一个bug吧？深入其中，追根溯源，直接看下字节码： 123456789101112131415import dis# 初始化链表n0 = ListNode(0)n1 = ListNode(1)n2 = ListNode(2)n3 = ListNode(3)n0.next = n1n1.next = n2n2.next = n3# 查看交换代码的字节码pre = Nonecur = n0dis.dis(\"cur, pre, cur.next = cur.next, cur, pre\") 输出是 123456789101112131415161718192021# 0-10步，先依次取右值 cur.next, cur, pre，然后倒序 0 LOAD_NAME 0 (cur) # 取cur值，push入栈 2 LOAD_ATTR 1 (next) # 取cur.next，替换栈顶 4 LOAD_NAME 0 (cur) # 取cur值，push入栈 6 LOAD_NAME 2 (pre) # 取pre值，push入栈 8 ROT_THREE10 ROT_TWO # ROT_3和ROT_2两步的效果，就是对栈内的3个元素倒序 # 目前栈内从顶至底分别为[old_cur_next, old_cur, old_pre]# 依次赋值左边变量，cur, pre, cur.next12 STORE_NAME 0 (cur) # pop栈顶，赋值给 cur (new_cur = old_cur_next) # 此时栈 [old_cur, old_pre]14 STORE_NAME 2 (pre) # pop栈顶，赋值给 pre (new_pre = old_cur) # 此时栈 [old_pre]16 LOAD_NAME 0 (cur) # 取cur值，push入栈 # 此时栈 [new_cur, old_pre]18 STORE_ATTR 1 (next) # 将栈顶元素(也就是cur)的next属性，赋值为栈的第二个元素 # new_cur.next = old_pre 关键在于第16步，重新load了一下cur，而此时cur已经在第12步，被赋值为old_cur_next。实际执行的是new_cur.next = old_pre，而我们的目标是old_cur.next = old_pre。因此出现了不一致。 关键在于 多元赋值中，左边被赋值的变量是有先后关系的。先改变了cur，那么再给cur.next赋值时，cur就已经是新的cur。因此如果同时需要改变cur、cur.next的值，应该优先赋值cur.next。 修改后的代码： 12345678def reverseList(head: ListNode) : pre = None cur = head while cur is not None: # cur, pre, cur.next = cur.next, cur, pre cur.next, pre, cur = pre, cur, cur.next return pre","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"剑指offer题目思路简结（三）","slug":"剑指offer题目思路简结（三）","date":"2020-06-25T01:36:29.000Z","updated":"2020-06-25T01:36:29.000Z","comments":true,"path":"2020/06/25/剑指offer题目思路简结（三）/","link":"","permalink":"http://yoursite.com/2020/06/25/%E5%89%91%E6%8C%87offer%E9%A2%98%E7%9B%AE%E6%80%9D%E8%B7%AF%E7%AE%80%E7%BB%93%EF%BC%88%E4%B8%89%EF%BC%89/","excerpt":"","text":"1. [剑指 Offer 50. 第一个只出现一次的字符](#剑指-offer-50-第一个只出现一次的字符) 2. [剑指 Offer 51. 数组中的逆序对](#剑指-offer-51-数组中的逆序对) 3. [剑指 Offer 52. 两个链表的第一个公共节点](#剑指-offer-52-两个链表的第一个公共节点) 4. [剑指 Offer 53 - I. 在排序数组中查找数字 I](#剑指-offer-53---i-在排序数组中查找数字-i) 5. [指 Offer 53 - II. 0～n-1中缺失的数字](#指-offer-53---ii-0n-1中缺失的数字) 6. [剑指 Offer 54. 二叉搜索树的第k大节点](#剑指-offer-54-二叉搜索树的第k大节点) 7. [剑指 Offer 55 - I. 二叉树的深度](#剑指-offer-55---i-二叉树的深度) 8. [剑指 Offer 55 - II. 平衡二叉树](#剑指-offer-55---ii-平衡二叉树) 9. [剑指 Offer 56 - I. 数组中数字出现的次数](#剑指-offer-56---i-数组中数字出现的次数) 10. [剑指 Offer 56 - II. 数组中数字出现的次数 II](#剑指-offer-56---ii-数组中数字出现的次数-ii) 11. [剑指 Offer 57 - II. 和为s的连续正数序列](#剑指-offer-57---ii-和为s的连续正数序列) 12. [剑指 Offer 58 - I. 翻转单词顺序](#剑指-offer-58---i-翻转单词顺序) 13. [剑指 Offer 58 - II. 左旋转字符串](#剑指-offer-58---ii-左旋转字符串) 14. [剑指 Offer 59 - I. 滑动窗口的最大值](#剑指-offer-59---i-滑动窗口的最大值) 15. [剑指 Offer 59 - II. 队列的最大值](#剑指-offer-59---ii-队列的最大值) 16. [剑指 Offer 60. n个骰子的点数](#剑指-offer-60-n个骰子的点数) 17. [剑指 Offer 61. 扑克牌中的顺子](#剑指-offer-61-扑克牌中的顺子) 18. [剑指 Offer 62. 圆圈中最后剩下的数字](#剑指-offer-62-圆圈中最后剩下的数字) 19. [剑指 Offer 63. 股票的最大利润](#剑指-offer-63-股票的最大利润) 20. [剑指 Offer 64. 求1+2+…+n](#剑指-offer-64-求12n) 21. [剑指 Offer 65. 不用加减乘除做加法](#剑指-offer-65-不用加减乘除做加法) 22. [剑指 Offer 66. 构建乘积数组](#剑指-offer-66-构建乘积数组) 23. [剑指 Offer 67. 把字符串转换成整数](#剑指-offer-67-把字符串转换成整数) 24. [剑指 Offer 68 - I. 二叉搜索树的最近公共祖先](#剑指-offer-68---i-二叉搜索树的最近公共祖先) 25. [剑指 Offer 68 - II. 二叉树的最近公共祖先](#剑指-offer-68---ii-二叉树的最近公共祖先) 完结散花 ~ 剑指 Offer 50. 第一个只出现一次的字符遍历字符串，搞个map记录字符出现次数。再次遍历字符串，遇到出现次数为 1 的就返回。 剑指 Offer 51. 数组中的逆序对这题值得hard难度。如果暴力解法，时间复杂度将是O(N^2)。比排序的O(NlogN)还大，那么可否先排序在比较，降低复杂度？比如 [7, 5, 6, 4] 先均分为两部分 [7, 5] 和 [6, 4]，分别排序得到，[5, 7] 和 [4, 6]。 对于5，发现只比4大，说明只有一个[5, 4]，对于7，继续与6比较，而不用继续跟4比较，说明有[7, 4]、[7, 6] 两个。 继续分别针对[7，5] 和 [6, 4] 重复 均分-&gt;排序-&gt;比较 这个过程。分别只有一个结果[7, 5]和[6, 4]。 所以最终结果为 5 123456789101112131415161718192021222324252627282930class Solution: def reversePairs(self, nums: List[int]) -&gt; int: # 比较两个排好序的子数组 def computePairs(arr1: List[int], arr2: List[int]) -&gt; int: if len(arr1) == 0 or len(arr2) == 0: return 0 l = 0 r = 0 res = 0 while l&lt;len(arr1) : while r &lt; len(arr2) and arr1[l] &gt; arr2[r]: r += 1 res += r l+=1 return res if len(nums) &lt;= 1: return 0 # 划分 &amp; 排序 nums2 = nums.copy() left_arr = nums[:len(nums2)//2] right_arr = nums[len(nums2)//2:] left_arr.sort() right_arr.sort() # 计算本身结果，并递归子数组 return computePairs(left_arr, right_arr) \\ + self.reversePairs(nums[:len(nums)//2]) \\ + self.reversePairs(nums[len(nums)//2:]) 剑指 Offer 52. 两个链表的第一个公共节点最简单的，先计算长度，然后比较两者的长度差，再利用快慢指针。一个巧妙的办法： 123456789101112class Solution: def getIntersectionNode(self, headA: ListNode, headB: ListNode) -&gt; ListNode: c1 = headA c2 = headB # 1. 最终c1和c2走的长度是相等的，LA + LB # 2. 如果不存在相交，c1走到B的结尾时会被赋值为None，此时c2也恰好走到A的结尾被赋值为None，刚好两者相等，跳出循环 while c1 != c2: c1 = c1.next if c1 else headB c2 = c2.next if c2 else headA return c1 剑指 Offer 53 - I. 在排序数组中查找数字 I先二分查找位置，再左右扩展。复杂度最差 O(N)，平均 O(logN) + O(M)。M为结果个数。如果M==N，则平均复杂度退化为 O(logN) + O(N)再优化一下，可以先查左边界，再查右边界。就是 O(logN) 的复杂度，避免了最差O(N)的复杂度。 都比暴力解法强吧 [doge][doge] 指 Offer 53 - II. 0～n-1中缺失的数字规律是：在缺失数左侧，每个数与其索引是相等的；在缺失数右侧，每个数 &gt; 其索引。因此可利用二分查找缺失数的位置。 剑指 Offer 54. 二叉搜索树的第k大节点按 右子树 -&gt; 根 -&gt; 左子树 的顺序遍历，使用全局变量记录还需遍历多少个节点。 1234567891011121314151617181920212223242526class Solution: def kthLargest(self, root: TreeNode, k: int) -&gt; int: # 返回 # 1. 是否找到 # 2. 对应的值 def dfs(r: TreeNode) -&gt; (bool, int): if r is None: return False, 0 # 遍历右子树 found, val = dfs(r.right) if found: return found, val # 遍历根 if self.nk == 1: return True, r.val self.nk -= 1 # 遍历左子树 return dfs(r.left) self.nk = k _, v = dfs(root) return v 剑指 Offer 55 - I. 二叉树的深度DFS，Depth(root) = 1 + max(Depth(root.left), Depth(root.right)) 剑指 Offer 55 - II. 平衡二叉树 解法一：计算并检查每一个节点左右子树的深度，但是这样做会有很多的重复计算。 解法二：自底向上，同时记录当前子树的深度，从而在计算父节点的深度时，避免重复计算。123456789101112131415161718192021# -1 表示非平衡，直接返回# &gt;=0 表示树的深度def valid(root: TreeNode) -&gt; (int): if root is None: return 0 left = valid(root.left) if left == -1: return -1 right = valid(root.right) if right == -1: return -1 if abs(left - right) &gt; 1: return -1 return max(left, right) + 1class Solution: def isBalanced(self, root: TreeNode) -&gt; bool: return valid(root) != -1 剑指 Offer 56 - I. 数组中数字出现的次数 如果一个数组中，只有一个数字出现了一次，其他数字都出现了两次，那么可以通过对所有数字进行xor操作，最后得到的就是该数 如果有两个数字a, b出现了一次，可以想办法将这两个数字划分到两个子数组，这两个子数组除下a, b外，其他都出现了两次，则可直接根据上述规律，xor遍历一遍得到a, b123456789101112131415161718192021class Solution: def singleNumbers(self, nums: List[int]) -&gt; List[int]: xor_res = 0 for v in nums: xor_res = xor_res ^ v # 找xor_res为1的那一位 # 也就是res1 和 res2 不同的那一位 div = 1 while (xor_res &amp; div) == 0: div = div &lt;&lt; 1 xor1 = 0 xor2 = 0 for v in nums: if v &amp; div == 0: xor1 = xor1 ^ v else: xor2 = xor2 ^ v return [xor1, xor2] 剑指 Offer 56 - II. 数组中数字出现的次数 II 解法一：遍历统计每个bit 1 出现的次数，最后对 3 取模即可。 解法二：还有个位运算的解，感觉没必要这么取巧。 剑指 Offer 57 - II. 和为s的连续正数序列滑动窗口，[i, j]表示连续子数组的两端，临时sum &lt;&gt; s，j右移扩大窗口，否则 i 左移缩小窗口。 剑指 Offer 58 - I. 翻转单词顺序split一下，然后倒序数组，最后拼接。 剑指 Offer 58 - II. 左旋转字符串切片操作，不做赘述。 剑指 Offer 59 - I. 滑动窗口的最大值这题标记为 easy 过分了。暴力解法就不说了，时间复杂度是 O(k*N)。可以优化一下，使用单调减的辅助队列（类似单调栈），来减少求每个窗口最大值时的遍历情况。复杂度为O(N)，因为辅助队列里的每个数，平均跟新进入队列的数，比较1次。（因为要么直接加入队列，要么，删掉队尾比它小元素，加入队列），被删掉的元素只会被比较 1 次。考虑极端情况，每个数都会加入辅助队列（原数组是递减的），则每次仍只需比较队尾元素和新加入元素 1 次。因此比较了 2N 次PS：单调栈和单调队列，是一个非常有帮助的思路。 剑指 Offer 59 - II. 队列的最大值类似 剑指 Offer 30. 包含min函数的栈，同样使用单调减的辅助队列。这题也可以称为”包含max函数的队列“。 剑指 Offer 60. n个骰子的点数这个题目描述得实在不好理解。 你需要用一个浮点数数组返回答案，其中第 i 个元素代表这 n 个骰子所能掷出的点数集合中第 i 小的那个的概率。 不过，写到这里，我发现用文字去描述一个算法思想，确实不太容易。至于这题，举个栗子，比如两个骰子，那么依次输出，抛出骰子的和为 2、3、4、5、6 …的概率。 首先可知，有 n 个骰子，那么结果范围为 [n, 6*n]，那么利用动态规划思想： 划分子问题：使用n个骰子抛出 x 的概率，等于使用一个骰子抛出 a 的概率 乘以 n-1 个骰子，抛出 x-a 的概率。一个骰子抛出各个值的概率自然是 1/6 状态转移公式：dp(n, x) = 1/6 * dp(n, x-a), 其中 a in [1, 6] 边界条件：dp(1, a) = 1/6，其中 a in [1, 6] 剑指 Offer 61. 扑克牌中的顺子除下0之外，数组不能重复。同时计算数组的最小值、最大值。（除 0 以外）判断 max_val - min_val 是否 &lt;= 4。 剑指 Offer 62. 圆圈中最后剩下的数字约瑟夫环，这特么竟然标记为简单！！！ 说是hard真不算过分。因为输出是最后剩下的数字，也正好是其下标。约瑟夫环的关键在于递推公式: F(N, M) = (F(N-1, M) + M) % N 其中，F(N,M)表示 N 个人时，某未被删除的数字的下标。假设 F(N,M) = y，在经过一次删除操作后，y的下标变为了 (y-M)%(N-1)，即 F(N-1, M)，设为 x。（因为 N 个数时，删除 M，会从第 M+1 处重新从 0 计算下标。被删除的 M 处于新数组的队尾，因此不会因为空洞之类的原因，影响新的下标计算。）根据 (y-M)%(N-1)=x 可推得： y = (x + M) % N 其实也好理解，相当于删除的逆过程，x左移M个位置，然后对N取余。 已知，F(1, M) = 0，因为1个人的时候，剩下数字的下标就是 0，那么可以递推出 F(1, M)，F(2, M) 直到 F(N, M)。 123456class Solution: def lastRemaining(self, n: int, m: int) -&gt; int: if n==1: return 0 return (m + self.lastRemaining(n-1, m)) % n 剑指 Offer 63. 股票的最大利润这个显然算 easy，却标记为 middle。不再啰嗦。 剑指 Offer 64. 求1+2+…+n这个妙在，利用 and / or 操作的执行顺序。已知： A and B，如果 A 为false，则 B 不会再执行 A or B，如果 A 为true，则 B 不会再执行 123456789101112class Solution: def sumNums(self, n: int) -&gt; int: self.res = 0 def sum(n: int): _ = n != 1 and self.sumNums(n - 1) # _ = n == 1 or self.sumNums(n - 1) self.res += n return True sum(n) return self.res 剑指 Offer 65. 不用加减乘除做加法这个特么又标为easy就离谱，里面的细节一点不少。两个数的相加，在二进制上可以表现为两部分： 直接相加，忽略进位：s1 = a ^ b，相同为0，不同为1 进位部分：s2 = (a &amp; b) &lt;&lt; 1，同为1的位，要向左进一位 两部分相加：sum = s1 + s2 剑指 Offer 66. 构建乘积数组使用两个辅助数组，分别计算从左到右，以及从右至左的乘积。再优化一下，可以只使用一个辅助数组。 剑指 Offer 67. 把字符串转换成整数难点在于检查中间结果是否溢出的条件，两种情况： res &gt; INT_MAX // 10，此时 res * 10，肯定溢出了 res == INT_MAX // 10 and cur_num &gt; 7，因为INT_MAX = 2147483647，如果 res 是正数，显然越界；如果 res 是负数，INT_MIN = -2147483648，所以满足这个条件的，只有 INT_MIN 本身。 剑指 Offer 68 - I. 二叉搜索树的最近公共祖先先分析下问题： 如果 p == root 或 q == root，那么 root 本身就是最近公共祖先 如果 p &lt; root &lt; q，那root一定是最近公共祖先 如果不满足 1，那么p和q 一定同时在 root 的左子树或右子树 上述root可能是某棵子树的根节点。 剑指 Offer 68 - II. 二叉树的最近公共祖先先分析下问题： 这是一棵普通二叉树，非搜索二叉树，各节点是无序的 最近公共祖先的定义不变，对于某节点来说，p/q 分别位于其左右子树；或其为p或q，并且q或p在其子树上；该节点就是最近公共祖先。 123456789101112131415161718192021222324class Solution: def lowestCommonAncestor(self, root: TreeNode, p: TreeNode, q: TreeNode) -&gt; TreeNode: if root is None: return None # 你可能有疑问，不用确定另一个在不再它的子树里吗？无需确定 # 假如root=p，若q在其子树里，root即为最近公共祖先； # 若q不在其子树里，那一定在别的子树里，此时会有left_res和right_res都不为None的时候，也就会返回对应的root if root.val == p.val or root.val == q.val: return root left_res = self.lowestCommonAncestor(root.left, p, q) right_res = self.lowestCommonAncestor(root.right, p, q) # p, q分别位于root的左右子树，root本身就是解 if left_res is not None and right_res is not None: return root # 到这里，left_res 和 right_res 一个为None，一个不为None # 情况1：某子树root==p或q，因此返回了自己，此时最近公共祖先，就是该子树的root。 # 就是left_res或right_res中不为空的那个。 # 情况2：某棵子树上发现了最近公共祖先，将其传递至最上层 return left_res if left_res else right_res 完结散花 ~","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"剑指offer题目思路简结（二）","slug":"剑指offer题目思路简结（二）","date":"2020-06-22T13:43:53.000Z","updated":"2020-06-22T13:43:53.000Z","comments":true,"path":"2020/06/22/剑指offer题目思路简结（二）/","link":"","permalink":"http://yoursite.com/2020/06/22/%E5%89%91%E6%8C%87offer%E9%A2%98%E7%9B%AE%E6%80%9D%E8%B7%AF%E7%AE%80%E7%BB%93%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"","text":"剑指 Offer 26. 树的子结构 剑指 Offer 27. 二叉树的镜像 剑指 Offer 28. 对称的二叉树 剑指 Offer 29. 顺时针打印矩阵 剑指 Offer 30. 包含min函数的栈 剑指 Offer 31. 栈的压入、弹出序列 剑指 Offer 32 - I. 从上到下打印二叉树 剑指 Offer 32 - II. 从上到下打印二叉树 II 剑指 Offer 32 - III. 从上到下打印二叉树 III 剑指 Offer 33. 二叉搜索树的后序遍历序列 剑指 Offer 34. 二叉树中和为某一值的路径 剑指 Offer 35. 复杂链表的复制 剑指 Offer 36. 二叉搜索树与双向链表 剑指 Offer 37. 序列化二叉树 剑指 Offer 38. 字符串的排列 剑指 Offer 39. 数组中出现次数超过一半的数字 剑指 Offer 40. 最小的k个数 剑指 Offer 41. 数据流中的中位数 剑指 Offer 42. 连续子数组的最大和 剑指 Offer 43. 1～n整数中1出现的次数 剑指 Offer 44. 数字序列中某一位的数字 剑指 Offer 45. 把数组排成最小的数 剑指 Offer 46. 把数字翻译成字符串 剑指 Offer 47. 礼物的最大价值 剑指 Offer 48. 最长不含重复字符的子字符串 剑指 Offer 49. 丑数 剑指 Offer 26. 树的子结构DFS判断各个子树，是否满足子树条件即可。树的结构，天生适合递归。 剑指 Offer 27. 二叉树的镜像递归交换左右子树的左右节点。 剑指 Offer 28. 对称的二叉树递归判断左右子树的左右节点。 剑指 Offer 29. 顺时针打印矩阵像洋葱一样，一层一层剥离打印。注意一些特殊情况，比如矩阵只有一行、一列的情况 剑指 Offer 30. 包含min函数的栈关键在于min的复杂度要求O(1)。这里需要用一个单调递减的栈，辅助实现。\b单调栈、单调队列在处理一些栈、队列最大值、最小值上很有用。 剑指 Offer 31. 栈的压入、弹出序列用一个栈去模拟压入、弹出过程，每当pop[0]==stack[-1]时，stack就弹出。如果pushed进栈完后，stack里还有数，则说明序列不对。 剑指 Offer 32 - I. 从上到下打印二叉树类似BFS，使用一个队列保存当前level的节点，之后依次遍历。 剑指 Offer 32 - II. 从上到下打印二叉树 II类似 剑指 Offer 32 - I. 从上到下打印二叉树，每层的结果单独保存即可。 剑指 Offer 32 - III. 从上到下打印二叉树 III类似 剑指 Offer 32 - I. 从上到下打印二叉树，每层的结果单独保存即可。使用一个flag来判断顺序还是逆序。 剑指 Offer 33. 二叉搜索树的后序遍历序列根据root节点，划分左右子树，递归判对即可。 剑指 Offer 34. 二叉树中和为某一值的路径递归DFS 剑指 Offer 35. 复杂链表的复制这题有意思，难得见到一个有意思的链表类的题。思路步骤： 复制：对每个节点都复制一个节点，并添加在其后面 拆分：对复制后的链表进行拆分，由于已知每个节点后面跟的，都是其复制节点，因此只需将复制节点的指向，也指向对应节点的复制节点，即可。 剑指 Offer 36. 二叉搜索树与双向链表对二叉搜索树模拟中序遍历，用一个指针记录遍历过程中的pre节点，最后将首尾相连，即可。 剑指 Offer 37. 序列化二叉树这题标记为hard，但实际上应该只算得上middle。 序列化：类似层次遍历，与 剑指 Offer 32 - I. 从上到下打印二叉树 相似。 反序列化：还是模拟层次遍历的过程 剑指 Offer 38. 字符串的排列这种排列组合、枚举类题，都可以用回溯思想来解决。和DFS类似，其实DFS是回溯思想在树、图之类的特殊场景里的一种表现。同DFS，回溯的常见实现方式也是递归。递归的时候，要小心大量的重复计算。（动态规划的递归实现中也存在） 通常要进行剪枝操作。因此也和动态规划的实现类似，可以使用备忘录法，或自底向上法。自底向上法效率最高，因为常常可以用循环迭代方式实现，减少递归调用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution: # 递归回溯，执行时间700ms def permutation1(self, s: str) -&gt; List[str]: if len(s) == 0: return [''] res = set() for i in range(0, len(s)): child_res = self.permutation1(s[:i] + s[i + 1:]) for v in child_res: res.add(s[i] + v) return list(res) # 备忘录，执行时间120ms def permutation2(self, s: str) -&gt; List[str]: seen = &#123;&#125; def perm(s2): if len(s2) == 0: return [''] if s2 in seen: return seen[s2] # 递归过程不变 res = set() for i in range(0, len(s2)): child_res = perm(s2[:i] + s2[i + 1:]) for v in child_res: res.add(s2[i:i + 1] + v) seen[s2] = list(res) return list(res) sorted_s = ''.join(sorted(s)) return perm(sorted_s) # 自底向上，执行时间80ms def permutation3(self, s: str) -&gt; List[str]: if len(s) == 0: return [''] res = set(s[0]) for c in s[1:]: new_set = set() for item in res: for i in range(0, len(item)+1): new_item = item[0:i] + c + item[i:] new_set.add(new_item) res = new_set return list(res) 剑指 Offer 39. 数组中出现次数超过一半的数字遍历一遍数组，记录一个数，及其出现次数。 剑指 Offer 40. 最小的k个数经典题目，两种解法： 利用容量为K的大顶堆，遍历一遍即可，比堆顶元素小的入堆，容量超过K时出堆 利用快排的二分思路，每次可以排除一批不满足条件的数，从而快速缩小查找范围 解法的关键思想在于，找最小的k个数，但是这k个数互相是不必排序的，因此尽力减少这部分排序操作。堆就减少了内部各个元素互相排序的操作。同样快排的二分思想，也可以一下子找到最大的m个数，m取决于所选的pivot。但是这m个数只需跟pivot比较，相互之间无需比较。 剑指 Offer 41. 数据流中的中位数这个有点妙。 使用两个堆，一个使用小顶堆，保存较大的一半数字；一个使用大顶堆，保存较小的一半数字。同时保持两个堆的元素数量相对平衡 0 &lt;= (大堆-小堆) &lt; 1。此时两个堆的堆顶元素，就是数据流中间的两个数。 在push时，将其和堆顶元素比较选一个堆加入。如果加入后，两个堆失去平衡，则进行调整 取中位数时，根据两个堆元素数是否相等可知，一共有奇数或偶数个数字。从而根据堆顶元素，计算中位数。 剑指 Offer 42. 连续子数组的最大和对于每一个元素，有两个选择，与前一个数字组成子数组，或重新开始计算子数组。记录遍历过程中的最大值。 剑指 Offer 43. 1～n整数中1出现的次数按个位、十位、百位…考虑，比如：输入314，分析过程如下 个位4，&gt;1，高位为31，受此影响，有 32 * 1 = 32 种可能 十位1，=1，高位为3，低位为4，受此影响，有 3*10 + 5 = 35 种可能 百位3，&gt;1，高位为0，受此影响，有 1*100 = 100 种可能 因此一共 32 + 35 + 100 = 167个。关键在于梳理清各种情况下1的个数。比如十位为1时，那么有01x/11x/21x，以及310~314，这么多种，也就是 3*10+5 = 35种。对于百位，当百位为1时，有1xx这么多种情况，所以就是 1 * 100种。 剑指 Offer 44. 数字序列中某一位的数字和 剑指 Offer 43. 1～n整数中1出现的次数 类似，关键在于找规律。可以发现:忽略0数字为1位的，从 1 开始，一共 9 个，1 - 9数字为2位的，从 10 开始，一共 90 个，10 - 99数字为3位的，从 100 开始，一共 900 个，100 - 999…依此可确定，第n位所在的区间，在取模可得到具体是哪个数字。大致思想如上，实现细节不再赘述。 剑指 Offer 45. 把数组排成最小的数一个取巧的办法，对数组进行自定义排序，从小到大。对于a、b两数的比较规则是，如果ab&gt;ba，则a&gt;b，否则a&lt;b。 剑指 Offer 46. 把数字翻译成字符串按动态规划的方式比较好理解： 划分子问题：每一位数字，既可以单独表示一个字母，也可以与后面数字组合，共同表示一个字母，如果&lt;26的话。 状态转移公式：F(s) = F(s[1:]) + F(s[2:]) 边界条件：len(s)&lt;=1时，F(s) = 1; 为什么 s 是空字符串时，F(s)也=1呢，s为空字符串，表示刚好划分完，仅此一种。比如12，F(12) = F(2) + F(“”)，F(“”)表示，12作为一个整体解释。 剑指 Offer 47. 礼物的最大价值很基础的动态规划题：按动态规划的方式比较好理解： 划分子问题：每一个格子可以分为，从上边格子和左边格子过来两种情况 状态转移公式：dp[i][j] = max(dp[i-1][j]+grid[i][j], dp[i][j-1]+grid[i][j]) 边界条件：第一行和第一列，单独处理 另外可以发现，dp[i][j]只和上一行有关，因此为了降低空间复杂度，可以只用一行空间即可。对 M*N 的格子，空间复杂度可以从 O(M * N) 降低至 O(M) 或 O(N) 剑指 Offer 48. 最长不含重复字符的子字符串使用两个指针 i, j，分别表示起始和结束。同时记录、更新某字符上次出现的位置。如果 j 指向的当前字符，上次出现的位置 k &gt; i，表示重复出现，则 i 更新为 k + 1。此时得到一个最长不重复子字符串，长度为 j-i。 剑指 Offer 49. 丑数下一个丑数为，当前丑数序列 * 2、3、5，得到的丑数中，最小的那个。为了避免重复计算，可以使用三个数，分别记录上一个乘以2、3、5后，就大于最新丑数的位置。 1234567891011121314151617181920212223class Solution: def nthUglyNumber(self, n: int) -&gt; int: if n == 1: return 1 dp = [0] * n dp[0] = 1 a, b, c = 0, 0, 0 for i in range(1, n): # 计算下一个丑数 aN, bN, cN = dp[a] * 2, dp[b] * 3, dp[c] * 5 # 选最小的 next = min(aN, bN, cN) dp[i] = next if next == aN: a += 1 if next == bN: b += 1 if next == cN: c += 1 return dp[-1]","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"剑指offer题目思路简结（一）","slug":"剑指offer题目思路简结（一）","date":"2020-06-22T06:54:13.000Z","updated":"2020-06-22T06:54:13.000Z","comments":true,"path":"2020/06/22/剑指offer题目思路简结（一）/","link":"","permalink":"http://yoursite.com/2020/06/22/%E5%89%91%E6%8C%87offer%E9%A2%98%E7%9B%AE%E6%80%9D%E8%B7%AF%E7%AE%80%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"剑指 Offer 03.数组中重复的数字 剑指 Offer 04. 二维数组中的查找 剑指 Offer 05. 替换空格 剑指 Offer 06. 从尾到头打印链表 剑指 Offer 07. 重建二叉树 剑指 Offer 09. 用两个栈实现队列 剑指 Offer 10- I. 斐波那契数列 剑指 Offer 10- II. 青蛙跳台阶问题 剑指 Offer 11. 旋转数组的最小数字 剑指 Offer 12. 矩阵中的路径 剑指 Offer 13. 机器人的运动范围 剑指 Offer 14- I. 剪绳子 剑指 Offer 14- II. 剪绳子 II 剑指 Offer 15. 二进制中1的个数 剑指 Offer 16. 数值的整数次方 剑指 Offer 17. 打印从1到最大的n位数 剑指 Offer 18. 删除链表的节点 剑指 Offer 19. 正则表达式匹配 剑指 Offer 20. 表示数值的字符串 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面 剑指 Offer 22. 链表中倒数第k个节点 剑指 Offer 24. 反转链表 剑指 Offer 25. 合并两个排序的链表 剑指 Offer 03.数组中重复的数字直接使用hash即可，高级一点的使用bitmap也可 剑指 Offer 04. 二维数组中的查找关键在于，利用规律缩小查找范围。 如果target &lt; 当前的数，那么它就不可能在target同一行的左边 每一列都按照从上到下递增的顺序排序：那么如果target &gt; 当前的数，那么它就不可能在target同一列的上面 从右上角开始找，一点一点缩小范围。 剑指 Offer 05. 替换空格 如果用python/java/golang之类的，可以直接拼接字符串。动态分配内存。 如果用c/c++，就需要预分配内存，因此需要先遍历一遍，计算有多少个空格，从而计算结果字符串所需内存大小。 剑指 Offer 06. 从尾到头打印链表 解法一：先遍历，再对结果数组反转 解法二：使用栈暂存节点，然后弹出栈 剑指 Offer 07. 重建二叉树关键点： 中序遍历的第一个节点，是当前节点的root；但是没法区分剩余节点，哪些是左、右子树 根据root，可以把前序遍历，分为左右子树两部分；借此得知左右子树的节点数量，也就能把中序遍历剩余节点分开 对中序遍历拆分的左右子树，递归求解 剑指 Offer 09. 用两个栈实现队列关键点： 两个栈，一个是input栈，一个是output栈，分别只负责input和output output没了，就从input里转移到output 时间复杂度，O(1)；空间复杂度，O(n) 剑指 Offer 10- I. 斐波那契数列递归、迭代解法，不再赘述。值得一提的是，对于递归类题目，有两个关键点： 递归子问题 递归终止条件，这个不能忘 尤其是二叉树类的问题，天生合适递归。把一个二叉树的问题，转换为，分别针对左右子树的两个子问题。 剑指 Offer 10- II. 青蛙跳台阶问题同 剑指 Offer 10- I. 斐波那契数列 斐波那契数列。 剑指 Offer 11. 旋转数组的最小数字二分法，确定min_index在[left, mid]，还是在[mid, right]之间。注意下极端条件，比如：翻转0个的情况；所有数都相等的情况；最后剩余两个数的情况；mid和边界相等的情况等等 剑指 Offer 12. 矩阵中的路径DFS 剑指 Offer 13. 机器人的运动范围BFS，当然DFS也可以，不过BFS最合适，相当于一圈一圈地扩展范围 剑指 Offer 14- I. 剪绳子简单的动态规划，顺带提一下动态规划的三个关键点： 划分子问题：一个大问题可以拆分为多个小问题，并且在大问题是最优解时， 状态转移公式 边界条件 是不是很像递归，因为动态规划一个最简单的实现方式就是递归。对于该题，三个关键点分别是： 划分子问题：长度为n的绳子，最大乘积，等于将其分一部分、两部分、多部分的最大值。 状态转移公式：F(n) = max( (n-i) * F[i] for i in range(1, n)) 边界条件：F(0) = 1; F(1) = 1 另外，由于该题要求至少分两段，因此需要对长度为最长时，稍微做一点特殊处理。 如果是递归实现，是会提示超时的，因为其中存在很多重复的计算。可以用递归的另外两种实现方式：备忘录法，自底向上法。 还有一种解法是根据数学规律，将n分为多个3。这种解法不具通用性，就不介绍了。 剑指 Offer 14- II. 剪绳子 II在 剑指 Offer 14- I. 剪绳子 基础上，多了大数，就直接使用long类型，然后取模吧。 剑指 Offer 15. 二进制中1的个数经典位运算题。n的每一位与 1 做 与操作，直到n变为0。 剑指 Offer 16. 数值的整数次方关键点，利用二分思想： 12pow(x, n) = pow(x, n//2) ** 2 # n为偶数 pow(x, n) = pow(x, n//2) ** 2 * x # n为奇数 剑指 Offer 17. 打印从1到最大的n位数最大的n位数，是 pow(10, n)-1，遍历即可。小心大数越界，如果是面试。 剑指 Offer 18. 删除链表的节点不再赘述。值得一提：链表类问题，可以增加一个头结点dummy_head，这样可以使边界情况，处理起来方便很多。 剑指 Offer 19. 正则表达式匹配动态规划：（主串S, 模式串T） 划分子问题：如果S和T匹配，那么S和T的子串也匹配 状态转移公式：为了避免每次都要检查，后一个字符串是否是”*”，从后往前遍历。 123456789101112131415161. T[i] 是普通字符 F(S, T) &#x3D; S[i] &#x3D;&#x3D; T[i] &amp;&amp; F(S[:-1], T[:-1])2. T[i] &#x3D;&#x3D; &#39;.&#39;，可以匹配任何字符 F(S, T) &#x3D; F(S[:-1], T[:-1])3. T[i] &#x3D;&#x3D; &#39;*&#39;，*前面的字符可以重复0次或多次 3.1 S&#x3D;&#x3D;&quot;&quot;, 说明*前面的字符重复0次 F(S, T) &#x3D; F(S, T[:-2]) 3.2 T[-2] &#x3D;&#x3D; &#39;.&#39; 或 S[-1] &#x3D;&#x3D; T[-2]，前一个字符能匹配上，则需考虑匹配0次、和多次的情况 F[S, T] &#x3D; F(S, T[:-2]) || F(S[:-1], T) 3.3 S[-1] !&#x3D; T[-2]，前一个字符不匹配，相当于匹配了0次 F(S, T) &#x3D; F(S, T[:-2]) 边界条件:边界条件，就是S、T一直递归匹配，直到某一个变为了空字符串 123451. S &#x3D;&#x3D; &quot;&quot; &amp;&amp; T &#x3D;&#x3D; &quot;&quot;，return True2. S &#x3D;&#x3D; &quot;&quot; &amp;&amp; T !&#x3D; &quot;&quot;, 需要继续匹配，比如 S&#x3D;”“， T&#x3D;&quot;a*&quot;，是匹配的3. S !&#x3D; &quot;&quot; &amp;&amp; T &#x3D;&#x3D; &quot;&quot;, return False 剑指 Offer 20. 表示数值的字符串非常典型的一道有限状态机题，重点在于划分不同的状态，怕错不怕重复。状态之间的转移相对容易。 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面两个指针，pre指针从头开始遍历，post指针指向尾。每次pre指向一个偶数，就将其与post交换，直到两指针相遇。 剑指 Offer 22. 链表中倒数第k个节点快慢指针，不做赘述。 剑指 Offer 24. 反转链表三个指针，循环遍历即可。注意边界条件。 剑指 Offer 25. 合并两个排序的链表添加一个dummy头结点，然后对两个链表，执行类似一个归并排序的操作。","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"}]},{"title":"人生的一些大道理","slug":"人生的一些大道理","date":"2020-06-11T08:25:13.000Z","updated":"2020-06-11T08:25:13.000Z","comments":true,"path":"2020/06/11/人生的一些大道理/","link":"","permalink":"http://yoursite.com/2020/06/11/%E4%BA%BA%E7%94%9F%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A4%A7%E9%81%93%E7%90%86/","excerpt":"","text":"虽然明明没啥资格去说人生这种大事，毕竟我也是第一次经历，并且只经历了一种人生。然鹅，还是想闲扯几句。也是看李笑来老师的书，说一下自己的想法。 问题1. 工作，还是睡懒觉？首先，单独就辛苦本身，不值得。 如果你家财万贯，衣食无忧，房车不缺，干嘛非得让自己辛苦？即使你没有大富大贵，但对目前的生活还挺满意，也不想着去追求更加丰富、昂贵的东西啦，更加崇高的地位啦，那也没必要辛辛苦苦。这两种情况，自己对什么有兴趣，就去做什么，这就挺好的呗~简直是我的理想生活啊！ 然鹅，无论出于什么原因，如果你想追求更好的，那辛苦就是值得的。 问题2. 生活是否公平？上帝是不公平的，付出了不一定有回报。上帝是公平的，不付出，就一定没有回报。 哪怕买彩票，也得多买几次，才更容易中奖不是？ 人很少会后悔做了哪些事，但是常常后悔没做哪些事儿。 另外，高考真的是人生最公平、公正的一次。而且大学这个烙印将陪伴你终身。高中要好好学习啊，弟弟妹妹们。大学就无所谓，想做其他事就去做，别挂科就行。 问题3. 你的，还是我的？街上碰到一个苹果，两个人同时看到了，这个苹果该属于谁呢？有人离得近，有人离得远，有人走过去，有人跑过去。不管怎样，先到达的那个有苹果吃。同样，有人生来就离苹果近，有人生来跑得快，有人毅力强能坚持。谁会是最后的赢家？我们不知道这个距离有多远，但是人生近百年，不是一场百米赛跑，而是一个马拉松。苹果，强者得之。所以，是我的。[doge] Respect ！","categories":[],"tags":[]},{"title":"从CAS到无锁队列.md","slug":"从CAS到无锁队列","date":"2020-06-03T09:24:15.000Z","updated":"2020-06-03T09:24:15.000Z","comments":true,"path":"2020/06/03/从CAS到无锁队列/","link":"","permalink":"http://yoursite.com/2020/06/03/%E4%BB%8ECAS%E5%88%B0%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97/","excerpt":"","text":"无锁算法多个线程读写同一内存，如何做到不加锁呢？其实没有那么高大上的算法在里面，实现无锁的前提是，硬件需支持”读取-更新-写入“的原子操作，比如 Test and Set, Fetch and Add, Compare and Swap等。以Compare and Swap，也就是CAS为例，可以实现很多无锁的数据结构，无锁队列，无锁树，区别在于需要几次的CAS。 CASbool CAS(type* addr, type val_old, type val_new)如果 addr 的值等于 val_old，就把它设置为 val_new，设置成功返回true，失败返回false。这个比较并赋值的操作，是一个原子操作。 无锁队列我们使用一个单向链表，作为无锁队列的基础数据结构。利用CAS的原子性，来保证在push/pop，也就是在链表尾/头添加、删除节点时，不会出现多线程互相覆盖的问题。 直接看代码: 123456// 很久没写C/CPP，语法细节忘了不少，忽略忽略struct &#123; node* tail // 尾指针 node* head // 头指针&#125;* Q 12345678910111213141516// Q是队列，data是待push的节点Push(Q, data)&#123; while true &#123; p = Q-&gt;tail; if CAS(p-&gt;next, NULL, data) &#123; // 如果此时p还是Q的tail，才能设置成功 break &#125; &#125; // 更新Q的tail，如果此时tail还是p，才能设置成功。 // 此时不用担心失败，因为如果此处不更新tail，其他线程拿到的总是旧的tail， // 其他线程在while循环中的CAS，会发现p-&gt;next!=NULL，就会失败, 一直处于while循环中 CAS(Q-&gt;tail, p, data)&#125; 123456789101112Pop(Q)&#123; while true &#123; p = Q-&gt;head if CAS(Q-&gt;head, p, p-&gt;next) &#123; break &#125; &#125; return p-&gt;value&#125; 由于CAS会直接用新值覆盖旧值，为了保存旧值，所以每次都会先把旧值取出来。然后在设新值时，要判断旧值是否发生了变化。那么以上实现有什么问题没？ 问题1，死循环考虑一些意外的情况。对于Push，如果线程第一个CAS执行成功，在执行第二个CAS时宕掉。此时 tail 未更新，其他线程会发现tail.next总是不为空，因此就会陷入while死循环。 问题2，ABA问题比如，一个线程按序执行了 pop -&gt; push操作，而push的节点，恰巧复用了被pop节点同一块内存。因为此链表例子中，CAS比较的是内存地址，所以校验通过。而里面的值其实是发生了变化的，如果不校验里面的值，可能会认为节点未被改动。 这两个问题如何解决呢？ 死循环问题 关键：tail节点未更新，导致CAS(p-&gt;next, NULL, data) 总是失败，因此可以让每个线程发现这个问题后，自己去更新tail节点。 ABA问题 节点增加计数器，每一次更新。计数的增减操作也需要原子化。 总结无锁数据结构的大致思想就是这样。借助CAS，一个极端的想法，所有程序都可以做成无锁的。只需要对任何一个变量的读写，都使用CAS操作，失败则从头开始。此时，虽然实现了无锁，但是效率却是降低的，\b因此，无锁也有它的适用场景 — 读多写少。因此此时CAS的冲突率比较小。与CAS比较像的一个机制，是自旋锁。自旋锁总是在尝试加锁，而CAS总是在尝试比较-修改，都算是忙等机制。","categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"算法","slug":"后端/算法","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法思想","slug":"算法思想","permalink":"http://yoursite.com/tags/%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3/"}]},{"title":"PathEscape与QueryEscape","slug":"PathEscape与QueryEscape","date":"2020-05-29T04:56:52.000Z","updated":"2020-05-29T04:56:52.000Z","comments":true,"path":"2020/05/29/PathEscape与QueryEscape/","link":"","permalink":"http://yoursite.com/2020/05/29/PathEscape%E4%B8%8EQueryEscape/","excerpt":"","text":"在给client种cookie时，发现个问题，种进去的加密cookie，解密时总报错。原因是：golang中，对一个字符串做url转义有两个方法，url.PathEscape()和url.QueryEscape。但是两个方法的行为有些区别。两者混用导致，编码和解码后，和原始字符串不一致。 1. 举个例子，直接对比下效果以 + 和 空格 这两个字符为例。 待转义字符 PathEscape QueryEscape PathUnEscape QueryUnEscape + + %2B + 空格 空格 %20 + 空格 空格 2. 具体功能2.1 PathEscape对特殊字符串进行转义，以便其可以作为url路径的一部分。就是URL地址两个 / 之间的部分 2.2 QueryEscape对特殊字符串进行转义，以便其可以作为url query的参数，也就是 ？后面那一串kv。 2.3 对比 两者的共同点在于：都会将一些特殊字符，转义为%AB的形式。特殊字符的定义为，除a-z，A-Z，0-9，- _ ~ · , / ; ? 的字符。 不同点在于：对于一些特殊字符，转义行为不同。 字符 PathEscpae QueryEscape $ Y N &amp; Y N + Y N : Y N = Y N @ Y N 具体的可参考RFC文档（URI、URL的两篇）和Golang的源码。（Golang源码更简单直接） 3. 其他其他语言似乎没分得那么清，具体实现上也有一些区别，比如python/javascript，encode行为就和golang的不一致。总之，同一语言，如golang，QueryEscape编码后，一定要配合QueryUnEscape使用。 一些细节也不同，比如JS里的encodeURI和encodeURIComponent。可以理解为，encodeURI，是把参数当做一个完整的URI在编码，而encodeURIComponent是把参数当做URI的一个segment。 12345678910111213// JS里encodeURI(\"12+34 56\")output: \"12+34%2056\"encodeURIComponent(\"12+34 56\")output: \"12%2B34%2056\"var a = \"http://www.ruanyifeng.com/blog/2010/02/url_encoding.html\"encodeURI(a)output: \"http://www.ruanyifeng.com/blog/2010/02/url_encoding.html\"encodeURIComponent(a)output: \"http%3A%2F%2Fwww.ruanyifeng.com%2Fblog%2F2010%2F02%2Furl_encoding.html\" 参考： http://www.ruanyifeng.com/blog/2010/02/url_encoding.html https://tools.ietf.org/html/rfc1738 https://tools.ietf.org/html/rfc3986","categories":[],"tags":[]},{"title":"关于工作的一些想法.md","slug":"关于工作的一些想法","date":"2020-05-28T06:36:40.000Z","updated":"2020-05-28T06:36:40.000Z","comments":true,"path":"2020/05/28/关于工作的一些想法/","link":"","permalink":"http://yoursite.com/2020/05/28/%E5%85%B3%E4%BA%8E%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"常见web安全总结","slug":"常见web安全总结","date":"2020-05-25T08:20:55.000Z","updated":"2020-05-25T08:20:55.000Z","comments":true,"path":"2020/05/25/常见web安全总结/","link":"","permalink":"http://yoursite.com/2020/05/25/%E5%B8%B8%E8%A7%81web%E5%AE%89%E5%85%A8%E6%80%BB%E7%BB%93/","excerpt":"","text":"XSS，跨站脚本攻击XSS的根本原因是，前端页面被嵌入一些恶意代码，这些恶意代码可能通过不同途径，注入进来。根据不同注入途径（或着说方式），可以分为反射型、持久型。 反射型XSS 恶意伪造url -&gt; 骗取用户点击 -&gt; 页面从url取参数进行渲染。从而参数里的恶意代码被执行。 案例：微博hellosamy事件 持久性XSS 在留言板、评论等场景提交恶意代码 -&gt; 后台未经处理，直接保存了前端提交的数据，-&gt; 再次访问或其他人访问时，前端展示相关内容，又把这些数据取出来进行渲染，从而恶意代码被执行。 案例：微信公众号XSS事件 应对： 用户提交的数据，入库前预处理，很多xssfilter 前端拼接Html时，也要做充分转义 为了防止cookie盗用，重要cookie设置http-only为true 参考 https://tech.meituan.com/2018/09/27/fe-security.html CSRF，跨站请求伪造（英語：Cross-site request forgery）本质是浏览器在发起请求时，会自动带上对应域名下的cookie。该特性可能导致，用户在访问恶意网站时，在用户不知不觉的情况下，触发一些携带了用户身份信息（cookie）的请求。如下图所示： 银行网站A，它以GET请求来完成银行转账的操作，如：http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000 危险网站B，它里面有一段HTML的代码如下： &lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; 首先，你登录了银行网站A，然后访问危险网站B，噢，这时你会发现你的银行账户少了1000块…… 在访问危险网站B的之前，你已经登录了银行网站A，而B中的img以GET的方式请求第三方资源（这里的第三方就是指银行网站了，原本这是一个合法的请求，但这里被不法分子利用了），你的浏览器会带上你的银行网站A的Cookie发出Get请求，去获取src指向的资源，结果银行网站服务器收到请求后，判断身份通过，所以就立刻进行转账操作…… 该例子里，一方面是由于用户上了小网站，另一方面，不应该用GET请求去更新资源（更改账户）。因为像src/script等标签都是默认用GET获取资源，如果再对前端熟悉一些的，可能会想到jsonp，就是利用script标签实现的。很多邮箱图片默认不展示，CSRF也是原因之一。当然还有很多其他的风险，这个可以单开一篇，开开脑洞。 vs 跨域？很多人会有疑问，浏览器不是有跨域限制吗，为什么还会出现在A页面，访问B服务器的情况。对于跨域请求，浏览器还是会正常发出，收到response后，会判断源和当前页面的源是否是属于同源，如果不属于，则需要根据access-control-allow-origin等header，判断server端是否允许跨域。 应对主要通过两个关键点： 虽然A网站可以向B服务器发请求，但是由于跨域限制，没法处理对应的response。因此一些更新资源的操作，最好用POST，更好的是使用restful风格。另一方面，也可以增加二次确认，比如引入验证码，实际上相当于一个动态的token。 由于正规的浏览器，对cookie访问，也要求同源。因此可以再query里增加一些cookie里才有的信息，在服务端校验query和cookie里对应的参数，如果不一致则为恶意。 其他的方法，还有增加referer，但是有的时候请求不带referer，比如非http协议页面发出的请求（ftp之类的）、https页面发出的http请求等，因此该方法有一定的漏洞。 SQL注入关键点： 1. 不要相信请求携带的参数，不要直接拿过来拼接SQL语句。SQL注入的防范很成熟，使用prepare statement即可，常用的client lib里都会实现。但是表名不支持参数化，因此表名还是得使用代码拼接的方式。这就要求表名不能是前端输入的，或者增加表名白名单校验。 从一条sql执行过程来说，编译 -&gt; 执行。一般情况是连带参数，一起编译，就会出现注入情况。 使用参数化查询的形式，会提前对模板进行预编译，而每个?占位的参数，只会被数据库当做一个完整的参数处理。","categories":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/categories/%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"MySQL知识点","slug":"MySQL知识点","date":"2020-05-20T03:09:35.000Z","updated":"2020-05-20T03:09:35.000Z","comments":true,"path":"2020/05/20/MySQL知识点/","link":"","permalink":"http://yoursite.com/2020/05/20/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"范式与反范式 范式 描述 反例 第一范式 每个字段都是原子的，不能再分解 某个字段是json串 第二范式 1. 表必须有主键；2. 非主属性，必须完全依赖主键，而不能只依赖主键的一部分字段。 好友关系表，关注人ID+被关注人ID作为主键，还存储了关注人的头像，这个只依赖于主键的一个字段。 第三范式 非主属性，直接依赖主键，而非间接依赖。 员工表，有部门ID和部门名称等，部门名称依赖部门ID，而不是员工ID，不应在员工表中。 分库分表比如电商订单表，有三个查询纬度：订单ID，用户ID，商户ID。 建立主纬度和辅助纬度之间的一个映射表比如，以订单ID拆分，那么要保存用户ID-&gt;订单ID和商户ID-&gt;订单ID的映射表。然而问题是： 映射表本身也要分表 每个订单，要写入多个库，属于分布式事务问题。通常会由后台任务，定时对比，保证多库表最终一致。 业务双写存多份数据，但是拆分纬度不一样。一套按用户ID划分，一套按商户号划分。同样存在写入多个库的分布式事务问题。 异步双写还是多份数据，业务单写一份，然后通过监听binlog，同步到其他表上 多个纬度统一到一个纬度比如把订单ID和用户ID统一成一个维度，然后把用户ID作为订单ID的一部分。这样，订单ID中就包含了用户ID的信息，然后按照用户ID分库，当按订单ID查询的时候，提取出用户ID，再按用户ID查询。 总之就是，拆分依据的维度，要同时在多个原始ID中提现 分库分表后的Join问题 join拆分为多个单表查询，在应用层代码里做join处理 增加宽表，提前join好 利用搜索引擎，比如ES，将DB数据导入ES中 分布式事务 最好是优化业务，避免跨库事务 如果无法避免，参考笔记：分布式事务一致性 B+树1. 优点相比hash索引，以及类似结构的KV缓存或数据库，有以下特性 范围查询 前缀匹配，模糊查询 排序和分页 2. 物理结构 磁盘属于块设备，innoDB读写磁盘，是以page为基本单位，page默认大小是16KB，每次I/O都是16KB的整数倍。 innoDB为每个Page赋予一个32位的全局编号，因此innoDB的存储上限是64T (2^32 * 16KB)。如果用来装非叶子节点，假如key是64位整数，也就是8字节，加上其他字段，按16字节算，一个page可以装1000个key。基于此估算，一个三层的B+树，可以存储的数据量： 第一层：根节点，一个page，1000个key。16KB内存，对应1000个子节点 第二层：1000个节点，每个节点一个page，每个page又可以有1000个子节点。16MB内存，对应1000 * 1000个子节点 第三层：1000 * 1000个节点，每个节点一个page。那么该表的最大容量是：1000 * 1000 * 16KB = 16GB。只需要16MB的内存索引，只需要一次I/O读取叶子节点 叶子page内部，以单向链表的方式，存储一条条的记录 非主键索引，索引树叶子节点存的是主键的value。 事务与锁1. 隔离级别 隔离级别 解决问题 Read Uncommited Read commited 解决脏读 Repeatable Read 解决幻读（通过间隙锁），innoDB默认级别。MVCC需要结合行锁，实现当前读，解决update时的覆盖问题。 Serialization 2. 死锁检测 判断一个有向图是否存在环，dfs、拓扑排序 死锁的发生，与代码有关，也与事务隔离级别有关，因为隔离级别会影响加锁机制。 复杂度是O(N) 3. innoDB的MVCC实现 每一行都有两个隐藏列，最近修改的事务ID + undolog里回滚段指针（便于回滚） 一致性视图，{low_trx_id, up_trx_id, trx_ids} low_trx_id: 当前事务链表，最小的事务id up_trx_id: 当前事务链表，最大的事务id trx_ids: 正在执行的事务的id集合通过比较当前事务id，与以上三个变量的关系，确定某个版本数据，是否对当前事务可见。 4. 事务实现1. WAL, Write-Ahead Log内存操作数据 + write-ahead log 2. Redo Log的逻辑与物理结构 redo log 物理组成结构 一个逻辑事务 包含 多个物理事务mtr，Mini Transaction 每个mtr对应一个LSN 一个LSN对应若干个连续的block 这些block，最终组成了 redo log 综上，一个事务在redo log里，可能有多个LSN，这些LSN自己是连续的，但是多个LSN不一定是连续的。 redo log 日志内容格式 先以page为单位记录日志 在每个page里面再采用物理记法 比如 (page id, record offset, (field1, value1)..(fieldi, valuei)…) Aries恢复算法 分析阶段从上一个checkpoint开始，开始分析哪些事务执行完了，未刷写page；哪些事务执行了一半，需要回滚。checkpoint机制，可以加快分析速度 redo阶段对已经commit的事务，执行redolog，刷写page。redolog是幂等的，重复执行没关系。 undo阶段对于未commit的事务，执行undolog，回滚 其他 每个page上记录了，上次修改的LSN，因此恢复时，如果redolog里的lsn&lt;page lsn，说明不用重写了。 redolog保证的是事务的持久性，写入成功，则不会丢失 3. Undo log redolog按LSN的顺序，而undolog没有顺序，多个事务并行写。每条日志除下记录主键ID和数据外，还有两个字段：修改记录的事务ID和回滚指针，用来串联所有历史版本，就是MVCC的两个隐藏列。 undo log 只在commit的过程中有用，一旦事务commit了，就可以删掉undo log 通俗一点，修改行前，先把行拷贝一份出来，这些历史版本形成一个链表。 各种锁 有不同的划分标准，比如按粒度，有表锁、行锁、gap锁；按锁的模式，有共享锁、排他锁、意向锁等 MySQL加锁问题与隔离级别有关，如果隔离级别是Read Commited，则不需要gap锁，因为RC允许幻读。 具体到各种锁 全局锁：对整个DB加锁，一些不支持事务的引擎，可以在备份前，锁住DB MDL，元数据锁：MDL分读/写，不需显式调用。MDL也是在语句执行时隐式加，在事务提交后释放。比如在对表做CURD时，加MDL读锁；对表做DDL时，加MDL写锁。 表锁，读/写，共享/排他，S/X 行锁，读/写，共享/排他，S/X 意向锁，意向锁也是表级别，但是意向锁之间互不排斥，包括IX（意向写）与IX也不互斥。意向锁的目的是提高在加表锁时的判断效率。如果事务要给表中某一行加X锁，首先要对表加IX锁；如果要给某一行加S锁，就先对表加IS锁。这也是“意向”一词的含义。如果一个事务要对表加X锁，就可以根据表有没有被其他事务加IS/IX锁，就可得知，有没有其他事务在读写该表。 间隙锁，解决幻读问题 AI锁，表级别，针对自增ID生成器，如果事务rollback，自增ID一列会不连续 其他问题 double write 机制 InnoDB的page size一般是16KB，其数据校验也是针对这16KB来计算的，将数据写入到磁盘是以page为单位进行操作的。操作系统写文件是以4KB作为单位的，磁盘IO是以512字节为单位的，那么每写一个InnoDB的page到磁盘上，操作系统需要写4个块。而计算机硬件和操作系统，在极端情况下（比如断电）往往并不能保证这一操作的原子性，16K的数据，写入4K时，发生了系统断电或系统崩溃，只有一部分写是成功的，这种情况下就是partial page write（部分页写入）问题。这时page数据出现不一样的情形，从而形成一个”断裂”的page，使数据产生混乱。这个时候InnoDB对这种块错误是无 能为力的. 有人会认为系统恢复后，MySQL可以根据redo log进行恢复，而MySQL在恢复的过程中是检查page的checksum，checksum就是pgae的最后事务号，发生partial page write问题时，page已经损坏，找不到该page中的事务号，就无法恢复。 为了解决该问题，写数据page时，写两遍到磁盘，第一遍是写到double write buffer文件上, 第二遍是从double write buffer写到真正的数据文件中。如果宕机重启，发现page损坏，可以从double write buffer中恢复。 因为redo log的写入单位就是512字节，也就是磁盘IO的最小单位，因此可以保证原子性，不会导致数据损坏。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"对CAP的正确理解","slug":"CAP","date":"2020-05-14T03:06:27.000Z","updated":"2020-05-14T03:06:27.000Z","comments":true,"path":"2020/05/14/CAP/","link":"","permalink":"http://yoursite.com/2020/05/14/CAP/","excerpt":"","text":"CAP C，一致性，多副本一致性，事务一致性等 A，可用性 P，分区容忍性 理解 最大的误解：CAP可以三选二实际上P是必然存在的，只能在C和A（一致性和可用性）之间权衡。实际中大多是AP或CP系统，很少有CA的系统。 AP系统，追求可用性，放弃一致性。比如MySQL主从等。 CP系统，追求强一致性，牺牲一定的可用性。raft、zab协议。而此时的一致性，也只是对客户端看来是一致的，对内部看，是最终一致，因为同步数据总需要时间。 对于CA系统，因为要实现A（高可用），就必然有冗余，有冗余就必然存在P。比如MySQL，内部事务实现强一致性C，但是单机无法保证A，单机也不存在网络延迟，因此可以满足P。 只要引入冗余，实现的高可用（A），就一定存在P。如果还想兼顾一致性（C），那么一定不是真的A。因此实际系统中，总是在CA之间做权衡。放弃某一方，就变成了AP或CP。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Map并发安全实现原理","slug":"map并发安全实现原理","date":"2020-05-14T03:03:32.000Z","updated":"2020-05-14T03:03:32.000Z","comments":true,"path":"2020/05/14/map并发安全实现原理/","link":"","permalink":"http://yoursite.com/2020/05/14/map%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","excerpt":"","text":"Java Concurrent hashmap 多个segment，支持最大segment数量的并发访问 ps: 如果hash桶的list过长，可以使用红黑树代替list golang sync.Map read-only, dirty 两个字段将读写分离 read-only不需加锁，读或写dirty都需要加锁 misses字段，统计read-only穿透次数，超过一定次数将dirty同步到read-only上 删除时，通过给read-only添加标记，延迟删除 读的时候，先查询read，不存在时查询dirty；写入时则只写入dirty 写入过程，每次写入时，先copy 未删除的read-only到dirty中，然后将k-v存入dirty。 read-only可以当做dirty的缓存。dirty里的数据，总比read-only的多。 适用于读多写少的场景。写入较多时，性能无法保证。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"各种树结构","slug":"各种树结构","date":"2020-05-13T02:21:07.000Z","updated":"2020-05-13T02:21:07.000Z","comments":true,"path":"2020/05/13/各种树结构/","link":"","permalink":"http://yoursite.com/2020/05/13/%E5%90%84%E7%A7%8D%E6%A0%91%E7%BB%93%E6%9E%84/","excerpt":"","text":"B树 vs B+树 vs B*树 B树，B是指发明人的名字 平衡多路搜索树 保持键值有序，以顺序遍历 使用不完全填充的节点块，来加速插入和删除 节点块至少半满，提升空间利用率 B+树 VS B树 非叶子节点，只保存索引：从而可以减少索引树的大小，内存里可以保存更多的索引。由于每次都需要走到叶子节点，查询时间也更稳定。 叶子节点之间，增加链指针，方便遍历 B*树在B+树的基础上 非根和非叶子节点，增加指向兄弟的指针 插入时，如果节点已满，会检查兄弟节点是否满，未满，则向兄弟节点转移数据；已满，则从当前节点和兄弟节点，各拿出1/3数据，创建一个新节点。从而节点空间利用率更高，节点分裂的情况也减少。 红黑树 也是一种BST(二叉搜索树)，但是不要求完全平衡 牺牲部分平衡性，达到较快的插入和删除性能 使用场景：linux CFS调度，nginx timer等 vs B树: B树作为多路搜索，能够在树深较小的情况下，支持更多的数据节点。对于磁盘类操作，可以避免大量的随机IO（一个磁盘page，可以读取到更多的索引，类似MySQL），从而优化读写性能。而红黑树一般整棵树都在内存里，不涉及到磁盘操作，支持的数据量较小，但是由于各种操作优于BST，因此常用于涉及到排序、搜索的场景。比如CFS，为了保证公平调度，每次选取当前执行总时间最小的线程执行。 LSM，Log-Structured Merged Tree 核心思想：放弃部分读性能，提高写性能。 适用于kv存储。 应用：rocksDB，levelDB，hbase rocksDB：c++编写的kv存储引擎，基于levelDB改造 levelDB：kv存储引擎 hbase: 分布式存储，列数据库，应对大量数据（亿级以上） 这些思想类似levelDB，但也有一些优化和改进，比如levelDB为了避免sstable过多，以及降低sstable合并过程中的开销，增加了level的概念。如果没有level，新sstable需要和旧的sstable比较，随着数据量的增多，新sstable需要和越来越多的sstable合并，从而效率降低。（如果每次合并后只留下一个大的sstable，效率一样会降低，因为涉及到插入操作。）有了level，上下层level，相关的sstable数量将会得到控制。从而加快压缩、合并的过程。 内存中的memtable，磁盘上的sstable。读取的时候，需要遍历sstable，这里的 优化是，使用是bloom filter，确定一个Key是否在sstable里。 一般LSM-Trees会配合内存排序，内存里将写数据缓冲（通常是一个红黑树、跳表之类的结构）。等积累得足够多之后，使用归并排序将数据合并，写入磁盘。 参考资料 http://blog.fatedier.com/2016/06/15/learn-lsm-tree/ lsm vs b+树 查询过程为了快速查询，一个办法是建立hash索引，但是hash索引占用空间太大，而且不支持区间查询。另一个办法是，事先对数据进行排序，B+树，把排序的操作放在了写入的时候，读的时候便轻松一些。 写过程 但是B树面对高并发写的时候，压力很大。B树把所有的压力都放到了写操作的时候，从根节点索引到数据存储的位置，可能需要多次读文件；真正插入的时候，又可能会引起page的分裂，多次写文件。 LSM在写的时候，直接写入内存，然后利用红黑树保持内存中的数据有序，由后台线程定期或被触发，去merge和持久化到磁盘。也会使用WAL方式记录log，避免数据丢失。 当写比读多时，LSM树相比于B树有更好的性能。因为随着insert操作，为了维护B树结构，节点分裂。读磁盘的随机读写概率会变大，性能会逐渐减弱。LSM把多次IO，批量变成一次IO，复用了磁盘寻道时间，极大提升效率。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"分布式锁","slug":"分布式锁","date":"2020-05-12T13:35:11.000Z","updated":"2020-05-12T13:35:11.000Z","comments":true,"path":"2020/05/12/分布式锁/","link":"","permalink":"http://yoursite.com/2020/05/12/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"redis set key val nx ex 优点：实现简单，性能好 缺点：超时时间不好控制，极端情况，会出现超时后，多个节点获取到同一把锁的情况。 问题 主从，redis主从采用异步复制，那么如果主机宕机，切换到从，会导致部分锁数据丢失。此时，多个client会拿到同一把锁。 如果锁没有设置超时，若client挂掉，则锁永远不会释放 如果锁设置了超时，若client阻塞或业务执行超时，也会导致多个client拿到同一把锁。 zookeeper 使用临时顺序节点，如果自己是子节点的第一个，则表示加锁成功。否则，watch上一个，如果上一个释放，表示轮到自己了。 优点：一般情况，不存在client宕机/超时问题，zk感知到client宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者取消自己的排队。 缺点：实现复杂，吞吐量不高 问题 因为zk使用心跳判断client是否在线，如果网络超时或者full GC等等，导致zk认为client宕机，则会释放锁。导致其他client同时获得该锁。但是这种情况很少见，相比之下，client处理超时这种更常见，这也是zk比redis方案好的原因。 mysql行锁 优点：不需引入额外中间件 缺点：吞吐量不高；也存在client宕机超时问题 总结 探测client是否宕机很难，如果因为超时，那就不应该释放锁。如果是因为宕机，那就应该释放锁。 没有完美的方案，实际场景中，分布式锁只应作为辅助手段，比如为了减少DB的压力等，不应仅靠它控制业务并发逻辑。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"方案总结","slug":"分布式/方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"高并发常见方案","slug":"高并发","date":"2020-05-12T13:29:38.000Z","updated":"2020-05-12T13:29:38.000Z","comments":true,"path":"2020/05/12/高并发/","link":"","permalink":"http://yoursite.com/2020/05/12/%E9%AB%98%E5%B9%B6%E5%8F%91/","excerpt":"","text":"高并发写 数据分片 数据库分库分表 JDK concurrentHashMap实现 kafka的partition ES的分布式索引 任务分片（计算） CPU的指令流水线 Map/Reduce Tomcat 1+N+M 网络模型：1个监听线程，N个IO线程负责对socket进行读写，M个worker对请求做逻辑处理。 异步化：异步接口、异步IO 短信验证码注册/登录 订单系统 广告计费系统，异步，多消息合并扣费 Kafka的Pipeline WAL技术 MySQL innoDB 的 redo log LSM树众多应用，levelDB等 批量 kafka的百万qps写入:partition分片，磁盘顺序写入，批量（leader/follower之间的批量，本地client之间的批量） mysql的group commit机制，对多事务的redo log批量flush 高并发读 加缓存 本地缓存/redis/memcached 增加副本冗余 MySQL master/slave CDN 静态文件加速 并发读 异步RPC 冗余请求，降低失败率","categories":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"方案总结","slug":"分布式/方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"多副本一致性","slug":"多副本一致性","date":"2020-05-12T03:23:33.000Z","updated":"2020-07-12T08:46:48.033Z","comments":true,"path":"2020/05/12/多副本一致性/","link":"","permalink":"http://yoursite.com/2020/05/12/%E5%A4%9A%E5%89%AF%E6%9C%AC%E4%B8%80%E8%87%B4%E6%80%A7/","excerpt":"","text":"同步本质每台机器都把收到的请求按日志存下来，各机器的日志文件保持一致。选择存储“事件流”，而非最终状态，原因是： 日志只有一种操作，append，相对简单 Paxos算法1. Basic Paxos 两个角色，Proposer 和 Acceptor，以及一个自增ID（n） 两个阶段，Propose阶段 和 Accept 阶段 Propose阶段 proposer广播消息，id为n，prepare(n) acceptor接收消息，如果n &gt; local N，则回复yes proposer收到半数以上的yes，开始广播，否则id自增，重新广播 Acctpt阶段 proposer广播消息, accept(n, value) acceptor接收消息，如果n &gt; loacal N，则持久化，返回yes proposer收到半数以上的yes，则结束。否则id自增，从proposer阶段重新开始。 两个问题 Paxos是个不断循环的2PC，有可能陷入死循环，所谓“活锁”。比如3个node同时propose，都收到no，又同时n++，继续propose，继续no 性能：每次写入，需要两次RTT + 两次写盘。两次RTT分别是Propose/Accept阶段。这两个阶段都会持久化一些变量，需要磁盘IO。 活锁问题 多点写入，变为单点写入。选出一个leader，只让leader当proposer。从而减少冲突。leader选取办法，比如每个节点增加编号，使用心跳，选取编号最大的节点为leader。即使出现同一时间，多个leader，也不影响paxos的正确性，只会增大并发写冲突的概率。 Raft算法 单点写入：任一时刻，只允许一个有效的leader存在，所有的写请求，都传到leader上，然后由leader同步给超过半数的follower。 单条日志结构：term + index + content。term是leader的任期，只会单调递增；index是日志顺序编号，也是递增； 分为三个阶段，选举阶段，正常阶段，恢复阶段 选举阶段 节点有三个状态：leader、follower、candidate。candidate是个中间状态。 当follower在一定时间收不到leader心跳时，就会随机sleep一个时间，然后变为candidate，发起选举。选举结束后，变为leader或follower。 选举算法，保证同一时间只有一个leader。 如果选举请求里，日志的term和index比自己本地的新，则返回true，否则返回false。 candidate收到多数派返回true，则成为leader 每个节点只能投一次true，防止多个leader。因此选取出的leader不一定是最新的，但一定比大多数节点新。 正常阶段，复制日志 只要超过半数的follower复制成功，就返回给客户端日志写入成功。 关键的日志一致性保证： 如果两个节点的日志，index和term相同，则内容一定相同。 如果index=M处的日志相同，则在M之前的日志，也一定相同。 恢复阶段 leader同步term给follower 以leader本地的日志为基准，复制给follower。这里比较特殊，如果新leader本身有未commit的日志，需要跟新的日志一起提交。避免一些特殊情况下，已commit的日志被覆盖。 安全性保证 leader数据是基准，leader不会从别的节点同步数据，只会是别的节点根据leader数据删除或追加自己的数据。 对于已经commit的日志，一定是commit的。对于新任leader上，前任leader未commit的日志，稍后会变为commit状态。不在新任leader上的未commit数据，会被覆盖。 Zabzookeeper使用的强一致性算法，同时也是单点写入，写请求都转发给leader。 模型对比，复制状态机(replicated state machine, paxos/raft) vs 主备系统（primay-backup system，zab）,前者持久化的是客户端的请求序列（日志序列），另外一个持久化的是数据的状态变化。 数据同步次数不一样，如果client执行三次x=1，后两次在主备系统里，不用触发同步。 存储状态变化，具有幂等性，而复制状态机不具备。 zxid 高32位，leader任期，类似raft的term 低32位，日志序列，类似raft的日志index 三个阶段：Leader选举，BroadCast,恢复阶段 Leader选举：FLE算法 Leader和Follower之间是双向心跳；raft里是单向 选取zxid最大的节点作为leader；和raft选取term+index最新的节点作为leader一个意思。 broadcast阶段 raft vs zab参考：https://my.oschina.net/pingpangkuangmo/blog/782702 上一轮残留的数据怎么处理？ 首先看下上一轮次的leader在挂或者失去leader位置之前，会有哪些数据？ 已过半复制的日志 未过半复制的日志一个日志是否被过半复制，是否被提交，这些信息是由leader才能知晓的， 那么下一个leader该如何来判定这些日志呢？ 下面分别来看看Raft和ZooKeeper的处理策略： Raft：对于之前term的过半或未过半复制的日志采取的是保守的策略，全部判定为未提交，只有当当前term的日志过半了，才会顺便将之前term的日志进行提交。 ZooKeeper：采取激进的策略，对于所有过半还是未过半的日志都判定为提交，都将其应用到状态机中 Raft的保守策略更多是因为Raft在leader选举完成之后，没有同步更新过程来保持和leader一致（在可以对外服务之前的这一同步过程）。而ZooKeeper是有该过程的","categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"系统原理","slug":"后端/系统原理","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"开天辟地","slug":"开天辟地","date":"2020-05-11T09:05:19.000Z","updated":"2020-05-14T03:04:18.669Z","comments":true,"path":"2020/05/11/开天辟地/","link":"","permalink":"http://yoursite.com/2020/05/11/%E5%BC%80%E5%A4%A9%E8%BE%9F%E5%9C%B0/","excerpt":"","text":"欢迎","categories":[],"tags":[]}],"categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"算法","slug":"后端/算法","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%AE%97%E6%B3%95/"},{"name":"安全","slug":"安全","permalink":"http://yoursite.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"方案总结","slug":"分布式/方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"},{"name":"系统原理","slug":"后端/系统原理","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"算法思想","slug":"算法思想","permalink":"http://yoursite.com/tags/%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3/"},{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/%E5%AE%89%E5%85%A8/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]}