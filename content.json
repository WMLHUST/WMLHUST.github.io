{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://yoursite.com","root":"/"},"pages":[{"title":"categories","date":"2020-05-11T09:14:14.000Z","updated":"2020-05-11T09:14:36.963Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2020-05-11T09:20:22.000Z","updated":"2020-05-11T09:22:25.642Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"about about"},{"title":"tags","date":"2020-05-11T09:10:36.000Z","updated":"2020-05-11T09:11:52.492Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"高并发常见方案","slug":"高并发","date":"2020-05-12T13:29:38.000Z","updated":"2020-05-12T13:29:38.000Z","comments":true,"path":"2020/05/12/高并发/","link":"","permalink":"http://yoursite.com/2020/05/12/%E9%AB%98%E5%B9%B6%E5%8F%91/","excerpt":"","text":"高并发写 数据分片 数据库分库分表 JDK concurrentHashMap实现 kafka的partition ES的分布式索引 任务分片 CPU的指令流水线 Map/Reduce Tomcat 1+N+M 网络模型：1个监听线程，N个IO线程负责对socket进行读写，M个worker对请求做逻辑处理。 异步化：异步接口、异步IO 短信验证码注册/登录 订单系统 广告计费系统，异步，多消息合并扣费 Kafka的Pipeline WAL技术 数据库redo log LSM树 批量 kafka的百万qps写入:partition分片，磁盘顺序写入，批量（leader/follower之间的批量，本地client之间的批量） mysql的group commit机制，对多事务的redo log批量flush 高并发读 加缓存 本地缓存/redis/memcached 增加副本冗余 MySQL master/slave CDN 静态文件加速 并发读 异步RPC 冗余请求，降低失败率","categories":[{"name":"分布式，方案总结","slug":"分布式，方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%8C%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"多副本一致性","slug":"多副本一致性","date":"2020-05-12T03:23:33.000Z","updated":"2020-05-12T05:09:02.394Z","comments":true,"path":"2020/05/12/多副本一致性/","link":"","permalink":"http://yoursite.com/2020/05/12/%E5%A4%9A%E5%89%AF%E6%9C%AC%E4%B8%80%E8%87%B4%E6%80%A7/","excerpt":"","text":"同步本质每台机器都把收到的请求按日志存下来，各机器的日志文件保持一致。选择存储“事件流”，而非最终状态，原因是： 日志只有一种操作，append，相对简单 Paxos算法1. Basic Paxos 两个角色，Proposer 和 Acceptor，以及一个自增ID（n） 两个阶段，Propose阶段 和 Accept 阶段 Propose阶段 proposer广播消息，id为n，prepare(n) acceptor接收消息，如果n &gt; local N，则回复yes proposer收到半数以上的yes，开始广播，否则id自增，重新广播 Acctpt阶段 proposer广播消息, accept(n, value) acceptor接收消息，如果n &gt; loacal N，则持久化，返回yes proposer收到半数以上的yes，则结束。否则id自增，从proposer阶段重新开始。 两个问题 Paxos是个不断循环的2PC，有可能陷入死循环，所谓“活锁”。比如3个node同时propose，都收到no，又同时n++，继续propose，继续no 性能：每次写入，需要两次RTT + 两次写盘。两次RTT分别是Propose/Accept阶段。这两个阶段都会持久化一些变量，需要磁盘IO。 活锁问题 多点写入，变为单点写入。选出一个leader，只让leader当proposer。从而减少冲突。leader选取办法，比如每个节点增加编号，使用心跳，选取编号最大的节点为leader。即使出现同一时间，多个leader，也不影响paxos的正确性，只会增大并发写冲突的概率。 Raft算法 单点写入：任一时刻，只允许一个有效的leader存在，所有的写请求，都传到leader上，然后由leader同步给超过半数的follower。 单条日志结构：term + index + content。term是leader的任期，只会单调递增；index是日志顺序编号，也是递增； 分为三个阶段，选举阶段，正常阶段，恢复阶段 选举阶段 节点有三个状态：leader、follower、candidate。candidate是个中间状态。 当follower在一定时间收不到leader心跳时，就会随机sleep一个时间，然后变为candidate，发起选举。选举结束后，变为leader或follower。 选举算法，保证同一时间只有一个leader。 如果选举请求里，日志的term和index比自己本地的新，则返回true，否则返回false。 candidate收到多数派返回true，则成为leader 每个节点只能投一次true，防止多个leader。因此选取出的leader不一定是最新的，但一定比大多数节点新。 正常阶段，复制日志 只要超过半数的follower复制成功，就返回给客户端日志写入成功。 关键的日志一致性保证： 如果两个节点的日志，index和term相同，则内容一定相同。 如果index=M处的日志相同，则在M之前的日志，也一定相同。 恢复阶段 leader同步term给follower 以leader本地的日志为基准，复制给follower 安全性保证 leader数据是基准，leader不会从别的节点同步数据，只会是别的节点根据leader数据删除或追加自己的数据。 对于已经commit的日志，一定是commit的。对于新任leader上，前任leader未commit的日志，稍后会变为commit状态。不在新任leader上的未commit数据，会被覆盖。 Zabzookeeper使用的强一致性算法，同时也是单点写入，写请求都转发给leader。 模型对比，复制状态机(replicated state machine, paxos/raft) vs 主备系统（primay-backup system，zab）,前者持久化的是客户端的请求序列（日志序列），另外一个持久化的是数据的状态变化。 数据同步次数不一样，如果client执行三次x=1，后两次在主备系统里，不用触发同步。 存储状态变化，具有幂等性，而复制状态机不具备。 zxid 高32位，leader任期，类似raft的term 低32位，日志序列，类似raft的日志index 三个阶段：Leader选举，BroadCast,恢复阶段 Leader选举：FLE算法 Leader和Follower之间是双向心跳；raft里是单向 选取zxid最大的节点作为leader；和raft选取term+index最新的节点作为leader一个意思。 broadcast阶段 raft vs zab参考：https://my.oschina.net/pingpangkuangmo/blog/782702 上一轮残留的数据怎么处理？ 首先看下上一轮次的leader在挂或者失去leader位置之前，会有哪些数据？ 已过半复制的日志 未过半复制的日志一个日志是否被过半复制，是否被提交，这些信息是由leader才能知晓的， 那么下一个leader该如何来判定这些日志呢？ 下面分别来看看Raft和ZooKeeper的处理策略： Raft：对于之前term的过半或未过半复制的日志采取的是保守的策略，全部判定为未提交，只有当当前term的日志过半了，才会顺便将之前term的日志进行提交 ZooKeeper：采取激进的策略，对于所有过半还是未过半的日志都判定为提交，都将其应用到状态机中 Raft的保守策略更多是因为Raft在leader选举完成之后，没有同步更新过程来保持和leader一致（在可以对外服务之前的这一同步过程）。而ZooKeeper是有该过程的","categories":[{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"系统原理","slug":"后端/系统原理","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"开天辟地.md","slug":"开天辟地","date":"2020-05-11T09:05:19.000Z","updated":"2020-05-11T09:13:22.465Z","comments":true,"path":"2020/05/11/开天辟地/","link":"","permalink":"http://yoursite.com/2020/05/11/%E5%BC%80%E5%A4%A9%E8%BE%9F%E5%9C%B0/","excerpt":"","text":"欢迎","categories":[],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://yoursite.com/tags/tag1/"}]}],"categories":[{"name":"分布式，方案总结","slug":"分布式，方案总结","permalink":"http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%8C%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"},{"name":"后端","slug":"后端","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/"},{"name":"系统原理","slug":"后端/系统原理","permalink":"http://yoursite.com/categories/%E5%90%8E%E7%AB%AF/%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"tag1","slug":"tag1","permalink":"http://yoursite.com/tags/tag1/"}]}