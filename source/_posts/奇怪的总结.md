---
title: 七七八八的知识点总结
tags: []
categories: []
comments: true
date: 2020-09-12 16:34:30
updated: 2020-09-12 16:34:30
description:
---

1. TCP/UDP 区别
    - UDP非连接
    - UDP包头短，因此效率相对高
    - 没有流控和拥塞控制

2. TCP拥塞控制
    - 加性增，未丢包，每收到一个确认，缓慢增加拥塞窗口(congWin)的值，目标是每个RTT，增加一个MSS，
    - 乘性减，发生丢包，减半拥塞窗口congWin的值
    - 慢启动，初始阶段，每个ACK，都将congWin增加一个MSS，此时是指数级增长   

    整体就是先慢启动，再遇到超时，进入加性增、乘性减的锯齿状态。congWin 取 min(当前congWin, 通告窗口)

3. TCP流量控制
匹配速度，使发送方的发送速率和接收方的读速率相匹配。避免接收方缓存溢出。
流量控制和拥塞控制，很像，但是是因为不同原因采取的措施。

1. TCP窗口大小
根据TCP报文段的接口窗口字段。
TCP全双工，因此连接两段都各自维护一个接收窗口。
```
接收窗口recv_win = recv_buff - last_recved。  
last_send - last_ack 需要小于 recvWin。

发送方依据接收到的接收窗口，称为`通告窗口`，计算可立即发送的数据。
```

5. TCP半连接  
syn flood 攻击，可通过syn cookies应对。通过src_ip/port等生成一个特殊的初始TCP序列号，在收到第三步的ack时，对比ACK是否=序列号+1。

6. TCP extension window scale 字段作用  
由于TCP header中，接收窗口只有16 bit，因此在一些高带宽场景利用率不足，所以才会额外使用一个window scale窗口因子，实际窗口的大小 = recv_win * 2^scale

1. TCP extension timestamp 字段作用
    - 更准确地计算RTT，如果没有ts，如果发生重传，收到ack时，不知道这个ack是针对第一个包的，还是第二次重传的包的
    - 在一些高带宽网络，可能短时间内会发生seq回环。增加ts后，由于ts递增，因此可以判断一个seq是否是回环包。

2. connection reset by peer
如果对端socket已关闭，则会收到该消息。从TCP协议上讲，比直接不回复更友好。  
一些选项，比如so_linger，为了避免close_wait，调用close()时，直接发送一个rst packet，注意此时缓冲区中的数据将会丢失。

7. broken pipe
进程收到收到SIGPIPE信号。信号是：如果一个 socket 在接收到了 RST packet 之后，程序仍然向这个 socket 写入数据，那么就会产生SIGPIPE信号。

1.  http错误码
    - 1XX：server收到请求，client继续执行操作；101，切换高级协议
    - 2XX：succ，201，请求succ并且创建了资源
    - 3XX：redirect，301永久，302临时
    - 4XX：client error，401未授权，400 badReq，403 forbidden，405 method not allow。
    - 5XX：server error，500 internal error，501 method not implement，502 bad gateway， 504 gw timeout，

2.  进程、线程 共享哪些资源  
共享：堆、代码段、公共数据(代码、全局变量、静态变量)、文件描述符等
线程独有：栈、寄存器、程序计数器

3.  Golang 内存分配、大对象、小对象、微对象   
底层都是调用runtime.mallocgc来分配内存，根据申请内存的大小，以及是否包含指针，会决定使用什么分配器。   
分配器：线性分配、Free-list、TCMalloc  
- 微对象: (0, 16b)，thread cache的tiny分配器
- 小对象: (16b, 32kb)，thread cache的span
- 大对象: (32kb, +∞)，page heap  
thread cache(mcache，无锁) -> central cache(加锁) -> page heap  
central cache的作用是，划分从mheap获得的内存为一个个span list，在thread cache的span不够时，划分给tc。而不用从page heap获取，然后划分等。  
mcache, mcentral, mheap是Go内存管理的三大组件，层层递进。mcache管理线程在本地缓存的mspan；mcentral管理全局的mspan供所有线程使用；mheap管理Go的所有动态分配内存

13.   性能调优方法   
命令：  
系统纬度：vmstat / iostat / netstat  
细节：pidstat / strace / ltrace / perf /proc-$pid-status统计信息等  
dmesg 内核环形缓冲，包括OOM、segment fault等，在/var/log/message也可以看到。

1.  GMP
2.  new、make区别
    - new 返回一个指针，make返回一个引用(slice/map/channel)
    - 底层都是相同的分配方法 mallocgc
3.  单例模式
```golang

```

```java
```
16. 读写锁 vs 互斥锁
读写锁不一定比互斥锁快，因为读写锁的加锁机制更复杂，如果并发线程较少，读写锁的优势体现不出来。读写锁的优势应该是，能够解决互斥锁只能有一个线程访问的问题。也就是说，单加、解锁，性能mutex > rwlock

17. Linux CPU调度
    1. O(1)
    - 很多的优先级，每个优先级一个FIFO队列
    - 使用bitmap记录哪个优先级待执行，便于快速定位待执行队列
    - 因为获取和插入都是O(1)因此成为O(1)调度器
    2. CFS
    - nice值，nice+120=优先级，会影响计算vruntime的系数
    - 维持vruntime红黑树，最左的节点就是下一个待执行的
18. Linux 内存分配
    1. buddy 算法
        - 一组链表，同一链表的块大小相等，2的幂次序列
        - 申请时候，寻找满足条件的（会有内存浪费，因为2的幂次相差太大了）
        - 归还时，检查相邻是否是空的，是则合并为更大的块
        - 分配单位是页，实际进程使用却是以字节，因此存在浪费

    2. slab 算法
        - 三个slab链表：slabs_full, slabs_partial, slabs_empty
        - 针对小对象，不为每个小对象分配一整个页，提高空间利用率
        - 一些小对象创建、销毁很频繁，对这些做缓存，可以重复利用，减少分配次数，从而提升分配效率
        - 在buddy系统之上，从buddy系统申请物理页

19. Golang 内存管理
    1. mcache: per-P cache，无锁
        - <16 byte的小对象会使用tiny分配器
        - 一组针对不同大小对象的链表（节点叫mspan），16byte~32kb的对象会寻找合适的分配，mspan用完了，则向mcentral申请，每个mspan有两类，根据对象是否含有指针决定，因为不含指针的对象，gc时无需主动扫描。
    2. mcentral：多P之间共享cache, mcache不够则向mcentral申请，mcentral同样有一组mspan链表，mcache来申请。
    3. mheap：mcentral不够，则向mheap申请，>32kb的大对象会直接向mheap申请。mheap也不够，则向os申请。总结，mheap的作用有两个，一是大对象分配；二是管理未切割的mspan

20. 内存分配器的目标
    1. 提升空间利用率
    2. 降低申请耗时     

21. timer 的几种实现  
    1. golang 四叉堆
        - 时间复杂度，插入：O(logN)，获取O(1)，删除O(logN)
        - 优点：精度更高
    2. nginx 红黑树
    3. 时间轮
        - 时间复杂度，插入、获取O(1)，删除O(N)，如果用链表存任务的话
        - 缺点：精度受限于时间轮的每一格
        - 优点：时间复杂度低，层级时间轮：能够表达跨度非常大的时间

22. Golang为什么从GM模型切换到GMP模型
    1. G在不同M间传递，导致的同步机制开销
    2. G在不同的M间传递，导致M的local cache失效，内存的空间局部性不好
    3. 系统调用导致M阻塞，不能充分利用获取到的CPU时间片资源